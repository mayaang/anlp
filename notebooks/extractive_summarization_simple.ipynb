{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extractive-summarization-simple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "alt-ctrl-e",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZUVIqj1_Vtk"
      },
      "source": [
        "# Simple Extractive Summarization based on word frequencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnR9rx5z5aHE"
      },
      "source": [
        "# Install and import ependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cU3eUkJA-Q2"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install pandas\n",
        "!pip install re\n",
        "!pip install pickle\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYWUMrHZ_Vup"
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from spacy.lang.pt.stop_words import STOP_WORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()f\n",
        "import unidecode\n",
        "from string import ascii_letters, punctuation\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G58PcEfxAIWs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQKUhP5C5q2I"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O00HvjZfA7wC"
      },
      "source": [
        "wikihow = pd.read_csv(r'/content/drive/MyDrive/summarization/wikihowAll.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppCTEEXyBDX1"
      },
      "source": [
        "wikihow = wikihow.astype(str)\n",
        "wikihow=wikihow[wikihow['text'].isnull()==False]\n",
        "wikihow=wikihow[wikihow['headline'].isnull()==False]\n",
        "wikihow=wikihow[wikihow['text']!='nan']\n",
        "wikihow.drop_duplicates(subset=['text'],inplace=True)\n",
        "wikihow['word_count'] = wikihow['text'].str.count(' ') + 1\n",
        "wikihow['headline_count'] = wikihow['headline'].str.count(' ') + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuldpEGoBGdr"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_all.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xvSEn_0W8ci"
      },
      "source": [
        "# pd.to_pickle(wikihow, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLZLHe0A6IJw"
      },
      "source": [
        "# wikihow_ = pd.read_pickle(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1xKqth7BMX1"
      },
      "source": [
        "contraction = { \n",
        "    \"ain't\": \"is not\", \n",
        "    \"aren't\": \"are not\", \n",
        "    \"can't\": \"cannot\", \n",
        "    \"'cause\": \"because\", \n",
        "    \"could've\": \"could have\", \n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\", \n",
        "    \"doesn't\": \"does not\", \n",
        "    \"don't\": \"do not\", \n",
        "    \"hadn't\": \"had not\", \n",
        "    \"hasn't\": \"has not\", \n",
        "    \"haven't\": \"have not\",\n",
        "    \"haven t\": \"have not\",\n",
        "    \"he'd\": \"he would\", \n",
        "    \"he'll\": \"he will\", \n",
        "    \"he's\": \"he is\", \n",
        "    \"how'd\": \"how did\", \n",
        "    \"how'd'y\": \"how do you\", \n",
        "    \"how'll\": \"how will\", \n",
        "    \"how's\": \"how is\",\n",
        "    \"I'd\": \"I would\", \n",
        "    \"I'd've\": \"I would have\", \n",
        "    \"I'll\": \"I will\", \n",
        "    \"I'll've\": \"I will have\", \n",
        "    \"I'm\": \"I am\", \n",
        "    \"I've\": \"I have\", \n",
        "    \"i'd\": \"i would\",\n",
        "    \"i'd've\": \"i would have\", \n",
        "    \"i'll\": \"i will\", \n",
        "    \"i'll've\": \"i will have\", \n",
        "    \"i'm\": \"i am\", \n",
        "    \"i've\": \"i have\", \n",
        "    \"isn't\": \"is not\", \n",
        "    \"it'd\": \"it would\",\n",
        "    \"it'd've\": \"it would have\", \n",
        "    \"it'll\": \"it will\", \n",
        "    \"it'll've\": \"it will have\", \n",
        "    \"it's\": \"it is\", \n",
        "    \"let's\": \"let us\", \n",
        "    \"ma'am\": \"madam\",\n",
        "    \"mayn't\": \"may not\", \n",
        "    \"might've\": \"might have\", \n",
        "    \"mightn't\": \"might not\", \n",
        "    \"mightn't've\": \"might not have\", \n",
        "    \"must've\": \"must have\",\n",
        "    \"mustn't\": \"must not\", \n",
        "    \"mustn't've\": \"must not have\", \n",
        "    \"needn't\": \"need not\", \n",
        "    \"needn't've\": \"need not have\", \n",
        "    \"o'clock\": \"of the clock\",\n",
        "    \"oughtn't\": \"ought not\", \n",
        "    \"oughtn't've\": \"ought not have\", \n",
        "    \"shan't\": \"shall not\", \n",
        "    \"sha'n't\": \"shall not\", \n",
        "    \"shan't've\": \"shall not have\",\n",
        "    \"she'd\": \"she would\", \n",
        "    \"she'd've\": \"she would have\", \n",
        "    \"she'll\": \"she will\", \n",
        "    \"she'll've\": \"she will have\", \n",
        "    \"she's\": \"she is\",\n",
        "    \"should've\": \"should have\", \n",
        "    \"shouldn't\": \"should not\", \n",
        "    \"shouldn't've\": \"should not have\", \n",
        "    \"so've\": \"so have\", \n",
        "    \"so's\": \"so as\",\n",
        "    \"this's\": \"this is\", \n",
        "    \"that'd\": \"that would\", \n",
        "    \"that'd've\": \"that would have\", \n",
        "    \"that's\": \"that is\", \n",
        "    \"there'd\": \"there would\",\n",
        "    \"there'd've\": \"there would have\", \n",
        "    \"there's\": \"there is\", \n",
        "    \"here's\": \"here is\", \n",
        "    \"they'd\": \"they would\", \n",
        "    \"they'd've\": \"they would have\",\n",
        "    \"they'll\": \"they will\", \n",
        "    \"they'll've\": \"they will have\", \n",
        "    \"they're\": \"they are\", \n",
        "    \"they've\": \"they have\", \n",
        "    \"to've\": \"to have\",\n",
        "    \"wasn't\": \"was not\", \n",
        "    \"we'd\": \"we would\", \n",
        "    \"we'd've\": \"we would have\", \n",
        "    \"we'll\": \"we will\", \n",
        "    \"we'll've\": \"we will have\", \n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\", \n",
        "    \"weren't\": \"were not\", \n",
        "    \"what'll\": \"what will\", \n",
        "    \"what'll've\": \"what will have\", \n",
        "    \"what're\": \"what are\",\n",
        "    \"what's\": \"what is\", \n",
        "    \"what've\": \"what have\", \n",
        "    \"when's\": \"when is\", \n",
        "    \"when've\": \"when have\", \n",
        "    \"where'd\": \"where did\", \n",
        "    \"where's\": \"where is\",\n",
        "    \"where've\": \"where have\", \n",
        "    \"who'll\": \"who will\", \n",
        "    \"who'll've\": \"who will have\", \n",
        "    \"who's\": \"who is\", \n",
        "    \"who've\": \"who have\",\n",
        "    \"why's\": \"why is\", \n",
        "    \"why've\": \"why have\", \n",
        "    \"will've\": \"will have\", \n",
        "    \"won't\": \"will not\", \n",
        "    \"won't've\": \"will not have\",\n",
        "    \"would've\": \"would have\", \n",
        "    \"wouldn't\": \"would not\", \n",
        "    \"wouldn't've\": \"would not have\", \n",
        "    \"y'all\": \"you all\",\n",
        "    \"y'all'd\": \"you all would\", \n",
        "    \"y'all'd've\": \"you all would have\", \n",
        "    \"y'all're\": \"you all are\", \n",
        "    \"y'all've\": \"you all have\",\n",
        "    \"you'd\": \"you would\", \n",
        "    \"you'd've\": \"you would have\", \n",
        "    \"you'll\": \"you will\", \n",
        "    \"you'll've\": \"you will have\",\n",
        "    \"you're\": \"you are\", \n",
        "    \"you've\": \"you have\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfPnlLN2BPy1"
      },
      "source": [
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJPw3BGBYyy"
      },
      "source": [
        "def clean(text):\n",
        "  text = text.lower()\n",
        "  text = unidecode.unidecode(text)\n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = ' '.join([contraction[t] if t in contraction else t for t in text.split(\" \")])\n",
        "  text = re.sub(r\"http\\S+\", \"\", text)\n",
        "  text = re.sub(r\"\\n\", \" \", text)\n",
        "  text = re.sub(r\"\\n\\n\", \" \", text)\n",
        "  text = re.sub(r\"'s\\b\",\"\",text)\n",
        "  text = re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
        "  text = text.strip(\" \")\n",
        "  text = re.sub('\"','', text)\n",
        "  text = re.sub(' +',' ', text).strip() \n",
        "\n",
        "  if len(text) != 0 and text[len(text)-1].isdigit():\n",
        "    text = text[0:len(text)-1]\n",
        "  return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNrNx4MUBa4B"
      },
      "source": [
        "wikihow[\"clean_title\"] = wikihow['title'].map(lambda text: clean(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiKpwV9yBdAJ"
      },
      "source": [
        "wikihow[\"clean_text\"] = wikihow['text'].map(lambda text: clean(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUNCkZkeBe_Y"
      },
      "source": [
        "wikihow[\"clean_headline\"] = wikihow['headline'].map(lambda text: clean(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p69RgHk9I_dc"
      },
      "source": [
        "## Pickle prepared data (test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o0mYK9RBicU"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_all_clean_extraction.pkl'\n",
        "pd.to_pickle(wikihow, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m2pfyWi_Vu4"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_all_clean_extraction.pkl'\n",
        "wikihow = pd.read_pickle(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4UjEoU-V2Qy"
      },
      "source": [
        "# Extract sentences based on simple frequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfqlOzV6_Vu7"
      },
      "source": [
        "def write_to(data, filename):\n",
        "    filehandler = open(filename, 'wb') \n",
        "    pickle.dump(data, filehandler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3w7rtupFmty"
      },
      "source": [
        "def extract_summary_for(text):\n",
        "\n",
        "    corpus = [sentence.text.lower() for sentence in text.sents ]\n",
        "\n",
        "    cv = CountVectorizer(stop_words=list(STOP_WORDS))   \n",
        "    cv_fit=cv.fit_transform(corpus)    \n",
        "    word_list = cv.get_feature_names();    \n",
        "    count_list = cv_fit.toarray().sum(axis=0)\n",
        "    word_frequency = dict(zip(word_list,count_list))\n",
        "    sorted_word_frequencies=sorted(word_frequency.values())\n",
        "    higher_word_frequencies = [word for word,freq in word_frequency.items() if freq in sorted_word_frequencies[-3:]]\n",
        "    higher_frequency = sorted_word_frequencies[-1]\n",
        "    for word in word_frequency.keys():  \n",
        "        word_frequency[word] = (word_frequency[word]/higher_frequency)\n",
        "    sentence_rank={}\n",
        "    for sentence in text.sents:\n",
        "        for word in sentence :       \n",
        "            if word.text.lower() in word_frequency.keys():            \n",
        "                if sentence in sentence_rank.keys():\n",
        "                    sentence_rank[sentence]+=word_frequency[word.text.lower()]\n",
        "                else:\n",
        "                    sentence_rank[sentence]=word_frequency[word.text.lower()]\n",
        "\n",
        "    top_sentences=(sorted(sentence_rank.values())[::-1])\n",
        "    top_three=top_sentences[:3]\n",
        "    summary=[]\n",
        "    for sentence,strength in sentence_rank.items():  \n",
        "        if strength in top_three:\n",
        "            summary.append(sentence)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return ''.join([s.text for s in summary])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNjm6YPJTSJ"
      },
      "source": [
        "# Summaries of short articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxsgo_mbBmEX"
      },
      "source": [
        "shorty = wikihow[\"word_count\"] < 800\n",
        "\n",
        "short_articles = wikihow[shorty].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1eMyd7xHuYJ"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_short_clean_extraction.pkl'\n",
        "pd.to_pickle(short_articles, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESlyKKr0ZF2z"
      },
      "source": [
        "short_articles['summary'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jypy-YwB8TA"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_short_clean_summary_extra.pkl'\n",
        "\n",
        "for ind in short_articles.index:\n",
        "  text = short_articles['clean_text'][ind]\n",
        "  doc = nlp(text)\n",
        "\n",
        "  try:\n",
        "    s = extract_summary_for(doc)\n",
        "  except ValueError:\n",
        "    print('error')\n",
        "    print(ind)\n",
        "    continue\n",
        "\n",
        "  short_articles['summary'][ind]=s\n",
        "\n",
        "  if ind >0 and ind % 100 == 0:\n",
        "    print('pickled')\n",
        "    pd.to_pickle(short_articles, path)\n",
        "    \n",
        "pd.to_pickle(short_articles, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ellYKpJeH1"
      },
      "source": [
        "# Summaries of shorter articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBrB8OQkZSlv"
      },
      "source": [
        "shortys = wikihow[\"word_count\"] < 300\n",
        "\n",
        "shorter_articles = wikihow[shortys].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6ZZNGzvZSl0"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_shorter_clean_extraction.pkl'\n",
        "pd.to_pickle(shorter_articles, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9beK-FpZSl1"
      },
      "source": [
        "shorter_articles['summary'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vTIfQNzZSl1"
      },
      "source": [
        "path = '/content/drive/MyDrive/summarization/wikihow_shorter_clean_summary_extra.pkl'\n",
        "\n",
        "for ind in shorter_articles.index:\n",
        "  text = shorter_articles['clean_text'][ind]\n",
        "  doc = nlp(text)\n",
        "\n",
        "  try:\n",
        "    s = extract_summary_for(doc)\n",
        "  except ValueError:\n",
        "    print('error')\n",
        "    print(ind)\n",
        "    continue\n",
        "\n",
        "  shorter_articles['summary'][ind]=s\n",
        "\n",
        "  if ind > 0 and ind % 100 == 0:\n",
        "    print('pickled')\n",
        "    pd.to_pickle(shorter_articles, path)\n",
        "    \n",
        "pd.to_pickle(shorter_articles, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNMNNJb89jU"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJDLO7hdada1"
      },
      "source": [
        "## Installation von nlg-eval, bleurt, functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRotatanao_4"
      },
      "source": [
        "import io\n",
        "\n",
        "def write_list_to(filename, da_list):\n",
        "  with open(filename, 'w') as f:\n",
        "    for item in da_list:\n",
        "      f.write(\"%s\\n\" % item)\n",
        "\n",
        "\n",
        "def calculate_bleurt(filename):\n",
        "  with io.open(filename,'r') as f:\n",
        "    bl = f.readlines()\n",
        "\n",
        "  b = [float(i) for i in bl]\n",
        "  score = sum(b)/len(b)\n",
        "  print('score for ' + filename)\n",
        "  print(score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bqWWRvDaq0p"
      },
      "source": [
        "!pip3 install git+https://github.com/Maluuba/nlg-eval.git@master\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIG3Yb0AatRc"
      },
      "source": [
        "!nlg-eval --setup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-_-A_T_ax6I"
      },
      "source": [
        "!git clone https://github.com/google-research/bleurt.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwDAY1wWa1NG"
      },
      "source": [
        "cd bleurt/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoCSOpkia2kF"
      },
      "source": [
        "!pip3 install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpm5D2LmbFJx"
      },
      "source": [
        "!python -m unittest bleurt.score_test\n",
        "!python -m unittest bleurt.score_not_eager_test\n",
        "!python -m unittest bleurt.finetune_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GFel2EabHHS"
      },
      "source": [
        "!wget https://storage.googleapis.com/bleurt-oss/bleurt-large-512.zip ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni_8PJbbbJqs"
      },
      "source": [
        "!unzip bleurt-large-512.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-h9ngmngT-z"
      },
      "source": [
        "## Short Articles summary evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e79n3UUnkS2"
      },
      "source": [
        "to_eval_hyp = short_articles['summary']\n",
        "to_eval_ref = short_articles['clean_headline']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bz4tURLoKLk"
      },
      "source": [
        "h_filename = '/content/drive/MyDrive/summarization/evaluation/short_articles_hypothesis.txt'\n",
        "r_filename = '/content/drive/MyDrive/summarization/evaluation/short_articles_reference.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0b3kUaaosRm"
      },
      "source": [
        "write_list_to(h_filename, to_eval_hyp)\n",
        "write_list_to(r_filename, to_eval_ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm0hOcT5QJ7m"
      },
      "source": [
        "!nlg-eval --hypothesis=/content/drive/MyDrive/summarization/evaluation/short_articles_hypothesis.txt --references=/content/drive/MyDrive/summarization/evaluation/short_articles_reference.txt --no-skipthoughts --no-glove "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAa6BwZ4hPmw"
      },
      "source": [
        "!python -m bleurt.score \\\n",
        "  -candidate_file=/content/drive/MyDrive/summarization/evaluation/short_articles_hypothesis.txt \\\n",
        "  -reference_file=/content/drive/MyDrive/summarization/evaluation/short_articles_reference.txt \\\n",
        "  -bleurt_checkpoint=/content/bleurt/bleurt-large-512\\\n",
        "  -scores_file=bleurt_scores_short_articles_summary.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2bHWFjthXmN"
      },
      "source": [
        "calculate_bleurt('bleurt_scores_short_articles_summary.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5SHmPBpglvJ"
      },
      "source": [
        "## Shorter Articles summary evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g38h_r5qghVy"
      },
      "source": [
        "to_eval_hyp = shorter_articles['summary']\n",
        "to_eval_ref = shorter_articles['clean_headline']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck6mtd9wghVz"
      },
      "source": [
        "h_filename = '/content/drive/MyDrive/summarization/evaluation/shorter_articles_hypothesis.txt'\n",
        "r_filename = '/content/drive/MyDrive/summarization/evaluation/shorter_articles_reference.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycY3WBajghVz"
      },
      "source": [
        "write_list_to(h_filename, to_eval_hyp)\n",
        "write_list_to(r_filename, to_eval_ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GE-oarXghVz"
      },
      "source": [
        "!nlg-eval --hypothesis=/content/drive/MyDrive/summarization/evaluation/shorter_articles_hypothesis.txt --references=/content/drive/MyDrive/summarization/evaluation/shorter_articles_reference.txt --no-skipthoughts --no-glove "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14F5_2LTg8XC"
      },
      "source": [
        "!python -m bleurt.score \\\n",
        "  -candidate_file=/content/drive/MyDrive/summarization/evaluation/shorter_articles_hypothesis.txt \\\n",
        "  -reference_file=/content/drive/MyDrive/summarization/evaluation/shorter_articles_reference.txt \\\n",
        "  -bleurt_checkpoint=/content/bleurt/bleurt-large-512\\\n",
        "  -scores_file=bleurt_scores_shorter_articles_summary.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwR-NKghUdK"
      },
      "source": [
        "calculate_bleurt('bleurt_scores_shorter_articles_summary.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfSUNxtvifqz"
      },
      "source": [
        "# Manual evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeAM78MAh0u1"
      },
      "source": [
        "with open(\"/content/guardian.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        guardian = \" \".join(f.readlines())\n",
        "doc = nlp(guardian)   \n",
        "s = extract_summary_for(doc)"
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}